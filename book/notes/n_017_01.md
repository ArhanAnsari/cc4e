The numeric values that are shown for characters are using the 
[ASCII](https://en.wikipedia.org/wiki/ASCII) character set. 
Character sets in the 1970's were quite intrictate.  Most were eight bits long
to conserve computer memory
and only support 100 or so supported Latin-like characters.  This is why early programming
languages use special characters like `*` and `{` in their syntax very carefully.
They needed to choose characters that were commonly available on computer keyboards from
different manufacturers.

Modern languages like Python 3 and Ruby store internal string values using the
[Unicode](https://en.wikipedia.org/wiki/Unicode) character set so they are
able to represent all characters in all languages around the world.  Modern languages
tend to represent eight bit values (range 0-256) using a `byte` or similar type.
Python 2 strings were stored as 8-bit bytes and Python 3 strings are stored as
32-bit Unicode characters.  Moving to Unicode was a major effort in the Python 2 to Python 3
transition.
