The 1970's was a time of transition in the amount of memory installed in computers.  The C language `int`
type was 16 bits in the older but more generally available computers like the PDP/11.  C could be used
to write programs like the UNIX operating that made efficient use of available memory.
In particular the 1978 version of C did not *require* that computers support 32 bit integers.
But 32,768 is a pretty small number.   The size of an integer affected
the maximum size of arrays and strings.  A lot of early C programs used the `long` type
to get at least a 32-bit integer
capable of representing numbers up to about two billion.  In modern computers and databases we tend to
choose between 32 bit and 64 bit integers.
