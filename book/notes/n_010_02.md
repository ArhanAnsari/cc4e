For those of you familiar with Python, before Python 3, integer division truncated and 
returned an integer, _just like C_.  In Python 3, one of the major improvements was that
the division of two integers performed the division operation in floating point and returns a floating point
result.

C and Python 2 made the choice because of efficiency.  Integer division with truncation (especially
for 16-bit numbers) was quite fast in 1970's computers compared to floating point division that kept the
fractional part intact.  Early PDP/11 computers did integer division in _hardware_ while floating point 
was done with loops and functions so it was far slower.  If you wanted to write fast code in the 1970's
you avoided floating point numbers except for in special situations.

Modern computers usually do 64-bit floating point operations at almost the same speed as integer division
so we don't need to allow programmers to avoid using floating point computations in their code.

